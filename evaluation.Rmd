% Human Gut Microbiome Viewed Across Age and Geography
% Hermann Pauly
% \today

Abstract
======

Soon to come...

Introduction
========

Hello fellow reader, I'm a document.

Methods and results
==============

<!--
## System information

```{r DisplayInfo}
require(cluster)
sessionInfo()
```
-->

16S rRNA data
-------------

### Data aquisition ###

I downloaded the raw data and metadata files from -[@MG-RAST] using the
UNIX command line tool *wget*.

### Preprocessing ###

#### Metadata mapping files ####

To categorize and compare genome data, a link between sequenced sample
files and their respective metadata is required. [@MG-RAST] provides a
mapping file between sample data files and unique IDs with incomplete
metadata, while [@Yats12] provide complete metadata file without
mapping to the sample data files. I applied the "calc" module of the
*LibreOffice* suite to combine the contents of both files to a
complete mapping file. For this I sorted both provided files' contents
by their sample ID strings and copy-pasted missing rows from the
MG-RAST mapping file into the metadata table. Two entries from the
mapping file were not found in the metadata table, and [@Yats12] also
stated that two samples could not be used in the analysis, so I
removed them from the metadata-mapping file. The result was saved as a
tab-seperated .csv file. On my system with German environment settings
I had to convert decimal values from comma-seperated values to
international dot-seperated format using the command line tool *sed*:

```
sed 's/,/\./g' 16s_mapping.csv > 16s_mapping_decimaldot.csv
```

The unique sequencer IDs differed from the sample IDs only by a
numerical appendix, so I used a Python script to check if all samples
were matched correctly:

~~~python
def checkSampleIDmapping(fileName):
    print "checking", fileName, "-->",
    csv = open(fileName, "r")
    count = 0
    errors = 0
    csv.readline() # skip header

    for line in csv:
        line_split = line.split('\t')
        try:
            longID = line_split[0]
            shortID = line_split[1]
            if not longID.startswith(shortID):
                print "error in line", count, shortID, longID
                errors += 1
        except:
            pass
        count += 1

    print "read", count, "samples,", errors, "errors"

for fileName in ["16s_mapping_decimaldot.csv", "wgs_mapping_decimaldot.csv"]:
    checkSampleIDmapping(fileName)
~~~

Calling the script produced the following output:

    checking 16s_mapping_decimaldot.csv --> read 528 samples, 0 errors
	checking wgs_mapping_decimaldot.csv --> read 110 samples, 0 errors  

#### $\alpha$- and $\beta$ diversity ####

Using the supported data and the manually created metadata mapping
table, I followed the QIIME workflow to create tables of OTU
abundances and analyse them for $\alpha$- and $\beta$ diversity.

The first step required is to categorize the sequenced microorganisms
into groups by phylogenetic distance. This step is called "picking". To
do this, I used the QIIME tool *pick\_closed\_reference.py*, which
compares the samples to an existing similarity tree. As picking
reference I used the GreenGenes database from 2011-02-04 and a
similarity threshold of 97%, as did [@Yats12]. The picking was done on
each sample individually, ten samples in parallel at any time, by
using the custom Python script *picking.py*.

The QIIME tools for $\alpha$-rarefaction and
$\beta$-diversity-analysis require a single biom table as input file,
so I combined the picking results. A try to combine all 528 sample
tables exceeded the computational power available, so I used the
custom Python script *combine.py* which creates a shell script that
calls the QIIME tool *merge\_otu\_tables.py* to iteratively add
sample tables to a common table. A copy of this table was converted to
a tab-seperated file (\texttt{combined.csv}) for easy use with *R*.

The following steps were all done with QIIME tools. To assess species
richness from the samples, the "rarefaction" technique is used. A
given population (here: microbiome inside a fecal sample) is
subsampled to calculate the overall species richness in the population
while keeping the sample size as small as possible and as big as
necessary. I used *alpha\_rarefaction.py* to create an overview of
suitable rarefaction depths.  
(TODO: nice rarefaction image here)
The read numbers per sample ranged from 305631 to 5826936, with a mean
of 1932291 and a median of 1884081. To guarantee that all samples are
represented and each one is subsampled I chose a rarefaction depth of
290000 (as compared to 290603 in the original publication), which is
less than the smallest sample's read count. I repeated the
rarefactioning ten times, using the tool
*multiple\_rarefaction\_even\_depth.py*.

From those rarefied OTU tables I calculated the $\alpha$- and $\beta$-diversity.
I calculated $\alpha$-diversity using the tool *alpha\_diversity.py*
with the number of observed species as a disance measure and merged
the results into a single table (\texttt{observed\_species.csv}) with the tool *collate\_alpha.py*.
To measure $\beta$-diversity I used UniFrac distance, the percentage
of shared branches on the phylogenetic tree, compared against the
GreenGenes reference tree. With the tool *beta\_diversity.py* I
calculated $\beta$-diversity distance matrices for all ten rarefied
tables, each with weighted and unweighted UniFrac distances as a
measure. The resulting files are called
\texttt{(unweighted\_)unifrac\_rarefaction\_290000\_N.txt}.

#### Load data from preprocessed files ####

```{r Initialisation}
theCountries <- c("Malawi", "USA", "Venezuela")
theColors <- c("red", "blue", "green")
names(theColors) <- theCountries
alphaTable <- read.delim("local_copy/observed_species.csv")
betaTable <- read.delim("local_copy/unweighted_unifrac_rarefaction_290000_4.txt")
rownames(betaTable) <- betaTable[,1]; betaTable <- betaTable[,-1]
theMetadata <- read.delim("16s_mapping_decimaldot.csv")
rownames(theMetadata) <- theMetadata$X.SampleID
colnames(theMetadata)
 # get sample ids with label of specific value
getGroupIDs <- function(label, value) {
  theMetadata[theMetadata[,label] %in% value,]$X.SampleID
}
 # get sample ids with label in numeric range
getRangeIDs <- function(label, lower, upper) {
  values <- theMetadata[,label]
  theMetadata[values >= lower & values <= upper,]$X.SampleID
}
 # get beta variance data for samples with given ids
getBetaGroup <- function(label=NULL, value=NULL, range=FALSE, ids=NULL) {
  if (length(ids) == 0) {
    if (any(is.na(c(label,value)))) { # no input at all
	  print("either label and value or ids required")
	  return(c())
	}
	if (!range)	ids <- getGroupIDs(label, value)
	else ids <- getRangeIDs(label, value[1], value[2])
  }
  betaTable[which(rownames(betaTable) %in% ids), which(colnames(betaTable) %in% ids)]
}
```
<!-- usable sample sizes: 188517 377024 -->

### UniFrac distance variation with age ###

[@Yats12] observed the change of microbiome composition from
infant-specific to adult configuration by comparing the composition of
each child's microbiome against the microbiome composition of all adults from the
same country. As it is not completely clear how the distance to all
adults was calculated I chose to use the mean of distances of the
child to each adult.

```{r DiversityChildToAdult, cache=TRUE}

plot(NULL, NULL, xlim=c(0, 18), ylim=c(0.35, 0.85), xlab="age", ylab="UniFrac distance")
country <- list(
    "USA" = getGroupIDs("Country", "USA"),
    "Malawi" = getGroupIDs("Country", "Malawi"),
    "Venezuela" = getGroupIDs("Country", "Venezuela")
    )
adults <- list(
    "USA" = intersect(country[["USA"]], getRangeIDs("Age", 19, 99)),
    "Malawi" = intersect(country[["Malawi"]], getRangeIDs("Age", 19, 99)),
    "Venezuela" = intersect(country[["Venezuela"]], getRangeIDs("Age", 19, 99))
    )
children <- list(
    "USA" = intersect(country[["USA"]], getRangeIDs("Age", 0, 18)),
    "Malawi" = intersect(country[["Malawi"]], getRangeIDs("Age", 0, 18)),
    "Venezuela" = intersect(country[["Venezuela"]], getRangeIDs("Age", 0, 18))
    )
for (country in theCountries) {
    for (child in children[[country]]) {
        betadiv <- getBetaGroup(ids=c(child, adults[[country]]))
        x <- theMetadata[theMetadata$X.SampleID==child,]$Age
        y <- sum(betadiv[child,]) / (nrow(betadiv) - 1)
        points(x, y, col=theColors[[country]], pch=20)
    }
}
legend(x=14, y=1.0, legend=theCountries, text.col=theColors)
```

The UniFrac distances start with high values at early ages, show a
strong decline until approximately three years of age and stay
steadily low until adulthood (see fig. 1).

### PCoA analysis of betadiversity

Partitioning Around Medoids (PAM) is a method of clustering data
points into a given number k of groups. It minimizes a global distance
function by randomly assigning one data point as starting center for
each group, iteratively swapping points and centers and assigning all
data points to the nearest center.
[@Yats12] used the $\beta$-distance matrix as a one-dimensional
dissimilarity measure for the PAM algorithm and chose k=3 clusters to
refind the samples' countries of origin in the microbiome composition.
I used the *pam* function from the *R* package *cluster* to repeat the
process.

```{r Clustering, cache=TRUE}

clu <- pam(betaTable, diss=TRUE, k=3, keep.diss=TRUE)
clusplot(clu, col.p=c("red","blue","green")[theMetadata[names(clu$clustering),]$Country], main="")
legend(x=0.1, y=-0.2, legend=theCountries, text.col=theColors)
# note: color order is different, because the pamobject$clustering vector has a different order
contTable <- table(clu$clustering, theMetadata[names(clu$clustering),]$Country)
contTable <- cbind(contTable[,2], contTable[,1], contTable[,3]) # correct order
contTable
sum(diag(contTable) / sum(contTable))
```

The plot shows a seperated, banana-shaped distribution of US Americans
and intermingled groups of Malawians and Venezuelans with
concentrations for each subgroups (see fig. 2). Using different
rarefaction tables showed similar results of circa 84 per cent correct
assignment.

### SVM classificator analysis of $\beta$-diversity ###

The PCoA plot (fig. 2) suggested that discrimination of samples by
microbiome diversity is possible. To improve the assignment I used the
implementation of support vector machines (SVM) in the *R* package
*e1071*. Support vector machines classify multi-dimensional datasets
by finding a hyperplane that seperates the classes among (a subset
of) their features. It solves the problem of seemingly inseperable
datasets by applying a "kernel function" that adds additional
dimensions to the data's used features.

I trained a SVM to discriminate the dataset by different subsets of the
OTUs that showed the greatest variance and compared the predicted
samples with their countries of origin, using tenfold cross validation.

```{r Classifiers, cache=TRUE}
require(e1071)
species <- read.delim("local_copy/combined.csv", sep="\t", header=TRUE)
rownames(species) <- species[,1]
species <- species[,-1]
species <- t(species) # now rows = samples, cols = OTU counts
 
reps <- 20
L <- nrow(species)
N <- L / reps
NPredictors <- 50
allOfThem <- 1:L
strength <- rep(0, len=reps)

for (i in 1:reps) {
    testSet <- sample(allOfThem, N)
    allOfThem <- allOfThem[-testSet]
    training <- c(1:L)[-testSet]
    variances <- apply(species[training,], 2, var)
    topVariables <- order(variances, decreasing=TRUE)[1:NPredictors]
    trnNames <- rownames(species)[training]
    tstNames <- rownames(species)[testSet]

    model <- svm(x=species[training,topVariables], y=theMetadata[trnNames,]$Country)
    prediction <- predict(model, species[testSet,topVariables])
    contingency <- table(prediction, theMetadata[tstNames,]$Country)
    strength[i] <- sum(diag(contingency)) / sum(contingency)
}

print(median(strength))
```

TODO: vary feature size, use full size

#### Classification with relative OTU abundances

```{r ClassifiersNormalized, cache=TRUE, echo=FALSE}
species <- apply(species, 2, function(x) x <- x / sum(x))

allOfThem <- 1:L
strength <- rep(0, len=reps)

for (i in 1:reps) {
    testSet <- sample(allOfThem, N)
    allOfThem <- allOfThem[-testSet]
    training <- c(1:L)[-testSet]
    variances <- apply(species[training,], 2, var)
    topVariables <- order(variances, decreasing=TRUE)[1:NPredictors]
    trnNames <- rownames(species)[training]
    tstNames <- rownames(species)[testSet]

    model <- svm(x=species[training,topVariables], y=theMetadata[trnNames,]$Country)
    prediction <- predict(model, species[testSet,topVariables])
    contingency <- table(prediction, theMetadata[tstNames,]$Country)
    strength[i] <- sum(diag(contingency)) / sum(contingency)
}

print(median(strength))
```


### Bacterial diversity with age ###

[@Yats12] found that the number of OTUs inside the fecal samples
increased with age. To verify this I calculated the means of OTU
counts found in the ten rarefaction steps for each sample and plotted
it against each samples' age.

```{r BacterialDiversityWithAge}
for (rarefaction in c(188517, 377024)) {
    alpha <-alphaTable[alphaTable$sequences.per.sample==rarefaction,][,4:ncol(alphaTable)]
	dma <- data.matrix(alpha)
	y <- rep(0.0, length=ncol(dma)*nrow(dma))
    counts <- colMeans(data.matrix(alpha))
    names(counts) <- colnames(alpha)
    x <- theMetadata[names(counts),]$Age
    cols <- c("green", "blue", "red")[theMetadata[names(counts),]$Country]
    plot(x, counts, col=cols, pch=20, ylab="Number of OTUs", xlab="Age", lab=c(20, 6, 7), main=rarefaction)
    legend(x=55, y=500, legend=theCountries, text.col=theColors)
 }
```x

TODO: WTF??? This works on the Linux box!

The plot shows an increasing number of OTUs with increasing age. Note
that there are no values for Malawians in the middle age range.

WGS shotgun sequences
-----------------------

## Mapping data ##

Manually created extended metadata mapping table as with 16S genome

## Preprocessing ##

* Paper: "preprocessing was done using custom Perl scripts and publicly available software tools"
* Filtering for degenerate sequences, duplicates: possible with custom script, but huge amounts of cpu time needed
* Further preprocessing unknown

Decisions

*   created a *filter\_wgs\_reads.py* and then *faster\_filter.py* for
    proof of concept, but didn't run them on the whole dataset 
*   downloaded data processed by automatized qiime workflow from
    MG-RAST (.stats files)
*   try to recreate findings with this (different?) data
*   found that even improved mapping files could not identify samples
    ->  decided to leat that part out

Discussion
=======

Feel free to speak your mind.

Software used
==========

The metadata mapping files were created using *LibreOffice* software
suite version 4.2.4.2.  
The QIIME workflow was followed using the *QIIME* suite of software
tools, version 1.8.0 as described by [@QIIME].  
Data analysis and visualization was done using the *R* statistical sofware
version 3.1.0 [-@R], the package *cluster* by [@cluster] for partitioning around medoids
and the package *e1071* by [@e1071] for support vector machine classifiers.  
The custom Python scripts mentioned in the scope of this document can
be found on
[my github page](https://github.com/hermann-p/yatsunenko-2012-microbiome).

References
========

