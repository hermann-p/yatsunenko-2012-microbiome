% Reproduction of "Human Gut Microbiome Viewed Across Age and Geography"
% Hermann Pauly
% \today

Abstract
======

Soon to come...

Introduction
========

In science we try to produce reliable and unambigous results, working hard to avoid
common pitfalls and sloppy work, and we expect the same from our fellow scientists.
Nevertheless, an unacceptable number of publications *(numbers)* contain grave errors
*(quote needed)*, which has lead to waning trust in science, among scientists as well
as in the general public. One feature of trustworthy scientific work is
reproducability. If a second person with proper knowledge analyses a researchers' data
and finds the same results, this is an indicator that the first scientist did work
correctly. *(or both are wrong ;-) )*  
Here I work on the data Yasunenko et al. published in 2012 along with their publication
"Human Gut Microbiome Viewed Across Age and Geography" in Nature magazine.
They sequenced genomic data of fecal samples from participants hailing from three
different countries. Using ANOVA post hoc testing they found significant diversities
among ages, geographic locations and families (see [@Yats12]).
I recreated calculations, data processing, and data visualisation following the
descriptions given in the original paper to check if their findings and conclusions
can be reproduced knowing nothing more than the published sequencer data.

Methods and results
==============

<!--
## System information

```{r DisplayInfo}
options(warn=-1)
require(cluster)
sessionInfo()
```
-->

## Data aquisition ##

I downloaded the raw data and metadata files from MG-RAST[@MG-RAST] using the
UNIX command line tool *wget*. They can be found under project ID
numbers 98 (whole genome shotgun sequences) and 401 (16S rRNA V4 sequences).

## Preprocessing ##

### Metadata mapping files ###

To categorize and compare genome data, a link between sequenced sample
files and their respective metadata is required. The MG-RAST database [@MG-RAST]
provides a
mapping file between sample data files and unique IDs with incomplete
metadata, while Yatsunenko et al. provide a complete metadata file without
mapping to the sample data files. I applied the "calc" module of the
*LibreOffice* suite to combine the contents of both files to a
complete mapping file. For this I sorted both provided files' contents
by their sample ID strings and copy-pasted missing rows from the
MG-RAST mapping file into the metadata table. Two entries from the
mapping file were not found in the metadata table, and Yatsunenko et al. also
stated that two samples could not be used in the analysis [@Yats12], so I
removed them from the metadata-mapping file. The result was saved as a
tab-separated .csv file. On my system with German environment settings
I had to convert decimal values from comma-separated values to
international dot-separated format using the command line tool *sed*:

```
sed 's/,/\./g' 16s_mapping.csv > 16s_mapping_decimaldot.csv
```

The unique sequencer IDs differed from the sample IDs only by a
numerical appendix, so I used the custom Python script
*checkSampleIDmapping.py* to check if all samples were matched
correctly. Calling the script produced the following output:

    checking 16s_mapping_decimaldot.csv --> read 528 samples, 0 errors
	checking wgs_mapping_decimaldot.csv --> read 110 samples, 0 errors  

### $\alpha$- and $\beta$ diversity ###

Using the supported data and the manually created metadata mapping
table, I followed the QIIME workflow to create tables of OTU
abundances and analyse them for $\alpha$- and $\beta$ diversity.

The first step required is to categorize the sequenced microorganisms
into groups by phylogenetic distance. This step is called "picking". To
do this, I used the QIIME tool *pick\_closed\_reference.py*, which
compares the samples to an existing similarity tree. As picking
reference I used the GreenGenes database from 2011-02-04 and a
similarity threshold of 97%, as did Yatsunenko et al. [@Yats12].
The picking was done on
each sample individually, ten samples in parallel at any time, by
using the custom Python script *picking.py*.

The QIIME tools for $\alpha$-rarefaction and
$\beta$-diversity-analysis require a single biom table as input file,
so I combined the picking results. A try to combine all 528 sample
tables exceeded the computational power available, so I used the
custom Python script *combine.py* which creates a shell script that
calls the QIIME tool *merge\_otu\_tables.py* to iteratively add
sample tables to a common table. A copy of this table was converted to
a tab-separated file (\texttt{combined.csv}) for easy use with *R*.

The following steps were all done with QIIME tools. To assess species
richness from the samples, the "rarefaction" technique is used. A
given population (here: microbiome inside a fecal sample) is
subsampled to calculate the overall species richness in the population
while keeping the sample size as small as possible and as big as
necessary. I used *alpha\_rarefaction.py* to create an overview of
suitable rarefaction depths.  
(TODO: nice rarefaction image here)
The read numbers per sample ranged from 305,631 to 5,826,936, with a mean
of 1,932,291 and a median of 1,884,081. To guarantee that all samples are
represented and each one is subsampled I chose a rarefaction depth of
290,000 (as compared to 290,603 in the original publication), which is
less than the smallest sample's read count. I repeated the
rarefactioning ten times, using the tool
*multiple\_rarefaction\_even\_depth.py*.

From those rarefied OTU tables I calculated the $\alpha$- and $\beta$-diversity.
I calculated $\alpha$-diversity using the tool *alpha\_diversity.py*
with the number of observed species as a disance measure and merged
the results into a single table (\texttt{observed\_species.csv}) with the tool *collate\_alpha.py*.
To measure $\beta$-diversity I used UniFrac distance, the percentage
of shared branches on the phylogenetic tree, compared against the
GreenGenes reference tree. With the tool *beta\_diversity.py* I
calculated $\beta$-diversity distance matrices for all ten rarefied
tables, each with weighted and unweighted UniFrac distances as a
measure. The resulting files are called
\texttt{(unweighted\_)unifrac\_rarefaction\_290000\_N.txt}.

### Load data from preprocessed files ###

I loaded the data files created by the previous steps 3.2.1 and 3.2.2
and created convenience access methods.

```{r Initialisation, echo=TRUE}
theCountries <- c("Malawi", "USA", "Venezuela")
theColors <- c("red", "blue", "green")
names(theColors) <- theCountries
alphaTable <- read.delim("local_copy/observed_species.csv")
betaTable <- read.delim("local_copy/unweighted_unifrac_rarefaction_290000_1.txt")
rownames(betaTable) <- betaTable[,1]; betaTable <- betaTable[,-1]
theMetadata <- read.delim("16s_mapping_decimaldot.csv")
 # sort tables by id-string-heads to make up for inconsistencies in id-string-tails
theMetadata <- theMetadata[order(rownames(theMetadata)),]
beta.order <- order(colnames(betaTable))
betaTable <- betaTable[beta.order,beta.order]
rownames(theMetadata) <- theMetadata$X.SampleID
 # get sample ids with label of specific value
getGroupIDs <- function(label, value) {
  theMetadata[theMetadata[,label] %in% value,]$X.SampleID
}
 # get sample ids with label in numeric range
getRangeIDs <- function(label, lower, upper) {
  values <- theMetadata[,label]
  theMetadata[values >= lower & values <= upper,]$X.SampleID
}
 # get beta variance data for samples with given ids
getBetaGroup <- function(label=NULL, value=NULL, range=FALSE, ids=NULL) {
  if (length(ids) == 0) {
    if (any(is.na(c(label,value)))) { # no input at all
	  print("either label and value or ids required")
	  return(c())
	}
	if (!range)	ids <- getGroupIDs(label, value)
	else ids <- getRangeIDs(label, value[1], value[2])
  }
  nums <- which(rownames(theMetadata) %in% ids)
  cat( length(nums), "of", length(ids), "can be retrieved\n")
  result <- betaTable[nums, nums]
  rownames(result) <- colnames(result)
  result
}
```

<!-- Useable sample sizes: 188517 or lower -->

## UniFrac distance variation with age ##

Yatsunenko et al. observed the change of microbiome composition from
infant-specific to adult configuration by comparing the composition of
each child's microbiome against the microbiome composition of all adults from the
same country [@Yats12]. As it is not completely clear how the distance to all
adults was calculated I chose to use the mean of distances of the
child to each adult.

```{r DiversityChildToAdult, cache=TRUE,echo=TRUE,fig.cap="The UniFrac distances start with high values at early ages, show a strong decline until approximately three years of age, and stay steadily low until adulthood."}

plot(NULL, NULL, xlim=c(0, 18), ylim=c(0.35, 0.85), xlab="age", ylab="UniFrac distance")
country <- list(
    "USA" = getGroupIDs("Country", "USA"),
    "Malawi" = getGroupIDs("Country", "Malawi"),
    "Venezuela" = getGroupIDs("Country", "Venezuela")
    )
adults <- list(
    "USA" = intersect(country[["USA"]], getRangeIDs("Age", 19, 99)),
    "Malawi" = intersect(country[["Malawi"]], getRangeIDs("Age", 19, 99)),
    "Venezuela" = intersect(country[["Venezuela"]], getRangeIDs("Age", 19, 99))
    )
children <- list(
    "USA" = intersect(country[["USA"]], getRangeIDs("Age", 0, 18)),
    "Malawi" = intersect(country[["Malawi"]], getRangeIDs("Age", 0, 18)),
    "Venezuela" = intersect(country[["Venezuela"]], getRangeIDs("Age", 0, 18))
    )
for (country in theCountries) {
    for (child in children[[country]]) {
        betadiv <- getBetaGroup(ids=c(child, adults[[country]]))
        x <- theMetadata[theMetadata$X.SampleID==child,]$Age
        y <- sum(betadiv[child,]) / (nrow(betadiv) - 1)
        points(x, y, col=theColors[[country]], pch=20)
    }
}
legend(x=14, y=1.0, legend=theCountries, text.col=theColors)
```

## PCoA analysis of $\beta$-diversity ##

Partitioning Around Medoids (PAM) is a method of clustering data
points into a given number k of groups. It initially assigns a data
point as center for each of the groups and then minimizes a global distance
function by iteratively swapping points and centers and assigning all
data points to the nearest new center.
Yatsunenko et al. used the $\beta$-distance matrix as a one-dimensional
dissimilarity measure for the PAM algorithm and chose k=3 clusters to
refind the samples' countries of origin in the microbiome composition
[@Yats12] of adults.

I used the *pam* function from the *R* package *cluster* to repeat the
process.

```{r Clustering, cache=FALSE, echo=TRUE, fig.cap="PCoA of beta-diversity among adults. Western samples can be linearly seperated. Many Malawian samples missing due to illegal data values."}
adultNames <- setdiff( rownames(theMetadata), getRangeIDs("Age", 0, 18) )
betaAdults <- getBetaGroup(ids=adultNames)
betaChldrn <- getBetaGroup("Age", c(0, 18), range=TRUE)
clu <- pam(betaAdults, diss=TRUE, k=3, keep.diss=TRUE)
clu2 <- pam(betaChldrn, diss=TRUE, k=3, keep.diss=TRUE)
par(mfrow=c(1,2))
clusplot(clu, col.p=c("red","blue","green")[theMetadata[names(clu$clustering),]$Country], main="")
clusplot(clu2, col.p=c("red","blue","green")[theMetadata[names(clu$clustering),]$Country], main="")
legend(x=0.15, y=-0.1, legend=theCountries, text.col=theColors)
 # note: color order is different, because the pamobject$clustering vector has a different order
contTable <- table(clu$clustering,
theMetadata[names(clu$clustering),]$Country)
 # correct order 
contTable <- cbind(contTable[,3], contTable[,1], contTable[,2])
pam.result <- sum(diag(contTable) / sum(contTable))
print(pam.result)
```

## SVM classificator analysis of $\beta$-diversity ##

The PCoA plot suggested that discrimination of samples by
microbiome diversity is possible. To improve the assignment I used the
implementation of support vector machines (SVM) in the *R* package
*e1071* [@e1071]. Support vector machines classify multi-dimensional datasets
by finding a hyperplane that separates the classes among (a subset
of) their features. They solve the problem of seemingly inseperable
datasets by applying a "kernel function" that adds additional
dimensions to the data's used features.

I trained a SVM to discriminate the dataset by different subsets of the
OTUs that showed the greatest variance and compared the predicted
samples with their countries of origin, using 20-fold cross validation.

```{r Classifiers, cache=TRUE,echo=TRUE,fig.cap="Barplots of SVM-classifier prediction of the 16S dataset. X-axis describes the number of features used. The features were selected by greatest variance. A blue horizontal line shows the prediction success of PAM clustering for comparison."}
require(e1071)
species <- read.delim("local_copy/combined.csv", sep="\t", header=TRUE)
rownames(species) <- species[,1]
species <- species[,-1] # species level OTU table
species <- t(species)   # now rows = samples, cols = OTU counts
reps <- 20              # number of repetitions for cross validation
L <- nrow(species)
N <- L / reps           # number of samples per validation run
featureSizes <- c(1:5, seq(10, 500, len=10), ncol(species)) # 
strength <- matrix(0, nrow=reps, ncol=length(featureSizes))
for (j in 1:length(featureSizes)) {
	allOfThem <- 1:L    # available samples
	for (i in 1:reps) {
		testSet <- sample(allOfThem, N)
		allOfThem <- allOfThem[-testSet]
		training <- c(1:L)[-testSet]
		variances <- apply(species[training,], 2, var)
		topVariables <- order(variances, decreasing=TRUE)
		topVariables <- topVariables[1:featureSizes[j]]
		trnNames <- rownames(species)[training]
		tstNames <- rownames(species)[testSet]
		model <- svm(x=species[training,topVariables], y=theMetadata[trnNames,]$Country);
		prediction <- predict(model, species[testSet,topVariables])
		contingency <- table(prediction, theMetadata[tstNames,]$Country)
		strength[i,j] <- sum(diag(contingency)) / sum(contingency)
	}
}
boxplot(strength, xlab="number of features", ylab="prediction success", axes=FALSE)
abline(h=pam.result, col="blue")
axis(side=1, at=1:length(featureSizes), labels=as.integer(featureSizes), las=2)
axis(side=2, at=seq(from=0, to=1.2, by=0.2))
```
<!-- all hail to the cache=TRUE parameter! -->

TODO: Draw evenly from all populations according to their
size. Improve feature sizes, include 90, as stated in the paper. Maybe
use p-values instead of variances (will be even slower).

## Bacterial diversity with age ##

Yatsunenko et al. found that the number of OTUs inside the fecal samples
increased with age [@Yats12]. To verify this I calculated the means of OTU
counts found in the ten rarefaction repetitions for each sample and plotted
them against each samples' age.

```{r BacterialDiversityWithAge, echo=TRUE, fig.cap="The number of OTUs per sample increases with age"}
rarefaction <- 188517
alpha <-alphaTable[alphaTable$sequences.per.sample==rarefaction,][,4:ncol(alphaTable)]
counts <- colMeans(data.matrix(alpha))
names(counts) <- colnames(alpha)
x <- theMetadata[names(counts),]$Age
cols <- c("green", "blue", "red")[theMetadata[names(counts),]$Country]
plot(x, counts, col=cols, pch=20, ylab="Number of OTUs", xlab="Age", lab=c(20, 6, 7))
legend(x=55, y=500, legend=theCountries, text.col=theColors)
```

TODO: Recompile on linux box, where the data doesn't "drop to the
floor". Find out, why these conversion errors appear on the Mac only.

## Processing of whole genome shotgun sequence data ##

*   Paper: "preprocessing was done using custom Perl scripts and publicly available
    software tools"
*   Filtering for degenerate sequences, duplicates: possible with custom script, but
    huge amounts of cpu time needed
*   Further preprocessing unknown

Decisions

*   created a *filter\_wgs\_reads.py* and then *faster\_filter.py* for
    proof of concept, but didn't run them on the whole dataset 
*   downloaded data processed by automatized qiime workflow from
    MG-RAST (.stats files)
*   try to recreate findings with this (different?) data
*   found that even improved mapping files could not identify samples
    ->  decided to ignore that part

\clearpage

## Software used ##

TODO: Integrate properly into methods

The metadata mapping files were created using *LibreOffice* software
suite version 4.2.4.2.  
The QIIME workflow was followed using the *QIIME* suite of software
tools, version 1.8.0 as described by Caporaso et al. [@QIIME].  
Data analysis and visualization was done using the *R* statistical sofware
version 3.1.0 [@R], the package *cluster* by Maechler et al. [@cluster] for
partitioning around medoids
and the package *e1071* by Meyer et al. [@e1071] for support vector machine
classifiers.  
The custom Python scripts mentioned in the scope of this document can
be found on
[my github page](https://github.com/hermann-p/yatsunenko-2012-microbiome).

Discussion
==========

Pro:

*   16S data analysis can be reproduced very well, plots virtually identical
*   conclusions very plausible
*   vast supplementary data available, so recreation of sample mapping possible

Con:

*   some minor vaguenesses in the description (eg "distance to all adults")
*   missing mapping files: this analysis relies very heavily on the mapping
    between samples and their metadata
*   no meaningful reproduction of WGS data possible due to lacking mapping file
    (Gigabytes of data useless because of one metafile)
*   switch from good description and documentation of 16S data to general,
	useless statements for WGS analysis ("custom scripts and publicly available
	tools")
*   PAM clustering of beta-div not very meaningful, SVM proved a lot
    better
*   number of unknown ages among Malawian population. How were the
    plotted in the original document?

References
==========

<!-- auto-filled by pandoc-citeproc -->
