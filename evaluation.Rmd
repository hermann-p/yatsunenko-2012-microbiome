% Title Human Gut Microbiome Viewed Across Age and Geography
% Author Hermann Pauly


## System information

```{r DisplayInfo}
require(cluster)
sessionInfo()
```

16S rRNA data
-------------

## Preprocessing

### Mapping files

* manually edit files in LibreOffice, save as tab-seperated .csv
* first method: recreation from supplementary .xlsl table
  * sample IDs present, metagenome IDs (= sample ID + number) not present
  * metagenome IDs recreated by parsing .fna files
  * 7 files cannot be mapped
* second method: use qiime run autogenerated mapping file
  * expand metadata table with info from qiime mapping file
  * result: *16s\_mapping.csv*
  * 2 identifiers found in qiime file that are not used in the study -> removed
  * on the German language system, don't forget to convert to intenational decimal number format:

```
sed 's/,/\./g' 16s_mapping.csv > 16s_mapping_decimaldot.csv
```

* do the same for the WGS shotgun data
* check if all ID-strings are consistently expanded sampleIDs

~~~python
def checkSampleIDmapping(fileName):
    print "checking", fileName, "-->",
    csv = open(fileName, "r")
    count = 0
    errors = 0
    csv.readline() # skip header

    for line in csv:
        line_split = line.split('\t')
        try:
            longID = line_split[0]
            shortID = line_split[1]
            if not longID.startswith(shortID):
                print "error in line", count, shortID, longID
                errors += 1
        except:
            pass
        count += 1

    print "read", count, "samples,", errors, "errors"

for fileName in ["16s_mapping_decimaldot.csv", "wgs_mapping_decimaldot.csv"]:
    checkSampleIDmapping(fileName)
~~~

> checking 16s_mapping_decimaldot.csv --> read 528 samples, 0 errors  
> checking wgs_mapping_decimaldot.csv --> read 110 samples, 0 errors  

### \alpha and \beta diversity

* *split\_libraries* already done
* no mapping file -> recreation from supplemantary .xls table
* different identificators -> recreate identificator strings from .fna files (*correct\_mapping\_ile.py*)
  * result: *mapping.csv*
* *pick\_closed\_reference* with parameters from original paper (very small wordlength), GreenGenes reference files
* combine .biom OTU-tables so alpha- and beta-diversity scripts can be run
* alpha:
  * *alpha\_rarefaction*  for overview
  * *multiple\_rarefactions\_even\_depth* to 290000 reads/sample (original: 290603)
  * *alpha\_diversity* measure observed\_species
  * *collate\_alpha* -> file *observed\_species.csv*
* beta
  * *beta\_diversity* with measures unifrac, weighted\_unifrac, GreenGenes reference tree -> files *(unweighted\_)unifrac\_rarefaction\_29000\_N.txt*


## Alpha diversity with age

### Loading and preparing

Read in files and init variables
```{r Initialisation}
theCountries <- c("USA", "Venezuela", "Malawi")
theColors <- c("blue", "green", "red")
names(theColors) <- theCountries
alphaTable <- read.delim("local_copy/observed_species.csv")
betaTable <- read.delim("local_copy/unweighted_unifrac_rarefaction_290000_4.txt")
rownames(betaTable) <- betaTable[,1]; betaTable <- betaTable[,-1]
theMetadata <- read.delim("local_copy/mapping.csv")
rownames(theMetadata) <- theMetadata$X.SampleID
colnames(theMetadata)
```

Define functions to select samples  
```{r DefineFunctions}
# get sample ids with label of specific value
getGroupIDs <- function(label, value) {
  theMetadata[theMetadata[,label] %in% value,]$X.SampleID
}

# get sample ids with label in numeric range
getRangeIDs <- function(label, lower, upper) {
  values <- theMetadata[,label]
  theMetadata[values >= lower & values <= upper,]$X.SampleID
}

# get beta variance data for samples with given ids
getBetaGroup <- function(label=NULL, value=NULL, range=FALSE, ids=NULL) {
  if (length(ids) == 0) {
    if (any(is.na(c(label,value)))) { # no input at all
	  print("either label and value or ids required")
	  return(c())
	}
	if (!range)	ids <- getGroupIDs(label, value)
	else ids <- getRangeIDs(label, value[1], value[2])
  }
  betaTable[which(rownames(betaTable) %in% ids), which(colnames(betaTable) %in% ids)]
}
```
<!-- usable sample sizes: 188517 377024 -->

### UniFrac distance variation with age

Nice plot in paper, but what exactly is plotted?  
x-axis: age  
y-axis: "UniFrac distance"
explanation: children vs unrelated adults of each country
So... mean of adults? median? some other measure?
assumption: mean of adults (gives nice similarity in plot)


#### Plot children against adults of same country (Todo: unrelated adults)

```{r DiversityChildToAdult}
{
    plot(NULL, NULL, xlim=c(0, 18), ylim=c(0.35, 0.85), xlab="age", ylab="UniFrac distance")
    country <- list(
        "USA" = getGroupIDs("Country", "USA"),
        "Malawi" = getGroupIDs("Country", "Malawi"),
        "Venezuela" = getGroupIDs("Country", "Venezuela")
        )
    adults <- list(
        "USA" = intersect(country[["USA"]], getRangeIDs("Age", 19, 99)),
        "Malawi" = intersect(country[["Malawi"]], getRangeIDs("Age", 19, 99)),
        "Venezuela" = intersect(country[["Venezuela"]], getRangeIDs("Age", 19, 99))
        )
    children <- list(
        "USA" = intersect(country[["USA"]], getRangeIDs("Age", 0, 18)),
        "Malawi" = intersect(country[["Malawi"]], getRangeIDs("Age", 0, 18)),
        "Venezuela" = intersect(country[["Venezuela"]], getRangeIDs("Age", 0, 18))
        )
    theColors <- list("USA"="blue", "Venezuela"="red", "Malawi"="green")
    for (country in c("USA", "Malawi", "Venezuela")) {
        for (child in children[[country]]) {
            betadiv <- getBetaGroup(ids=c(child, adults[[country]]))
            x <- theMetadata[theMetadata$X.SampleID==child,]$Age
            y <- sum(betadiv[child,]) / (nrow(betadiv) - 1)
            points(x, y, col=theColors[[country]], pch=20)
        }
    }
    legend(x=14, y=1.0, legend=theCountries, text.col=theColors)
}
```

Where are the Malawians?
Answer: x-position = age, many Malawians have *NA* entries for Age
How were they plotted in the publication?

## PCoA analysis of betadiversity

```{r PCoA_Analysis}
{
    clu <- pam(betaTable, diss=TRUE, k=3, keep.diss=TRUE)
    clusplot(clu, col.p=c("red","blue","green")[theMetadata[names(clu$clustering),]$Country], main="")
    legend(x=0.1, y=-0.2, legend=theCountries, text.col=theColors)
    # note: color order is different, because the pamobject$clustering vector has a different order
    contTable <- table(clu$clustering, theMetadata[names(clu$clustering),]$Country)
    contTable <- cbind(contTable[,2], contTable[,1], contTable[,3]) # correct order
    contTable
    sum(diag(contTable) / sum(contTable))
}
```

# Bacterial diversity with age

```{r BacterialDiversityWithAge}
par(mfrow=c(1,2))
for (rarefaction in c(188517, 377024)) {
    alpha <- alphaTable[alphaTable$sequences.per.sample==rarefaction,][,4:ncol(alphaTable)]
    counts <- colMeans(alpha)
    names(counts) <- colnames(alpha)
    summary(counts)
    x <- theMetadata[names(counts),]$Age
    cols <- c("green", "blue", "red")[theMetadata[names(counts),]$Country]
    plot(x, counts, col=cols, pch=20, ylab="Number of OTUs", xlab="Age", lab=c(20, 6, 7), main=rarefaction)
    legend(x=55, y=500, legend=theCountries, text.col=theColors)
}
```

WGS shotgun sequences
-----------------------

## Mapping data

Manually created extended metadata mapping table as with 16S genome

## Preprocessing

* Paper: "preprocessing was done using custom Perl scripts and publicly available software tools"
* Filtering for degenerate sequences, duplicates: possible with custom script, but huge amounts of cpu time needed
* Further preprocessing unknown

Decisions  
* created a *filter\_wgs\_reads.py* and then *faster\_filter.py* for proof of concept, but didn't run them on the whole dataset
* downloaded data processed by automatized qiime workflow from MG-RAST (.stats files)
* try to recreate findings with this (different?) data
